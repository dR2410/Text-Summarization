{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "sPEzfLI6vQ8u"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yLKBJCwAv9QN"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "# import plotly.express as px\n",
    "# import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1ubUtu8RvlJr"
   },
   "outputs": [],
   "source": [
    "class DontPatronizeMe:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # self.train_path = train_path\n",
    "#         self.test_path = test_path\n",
    "        self.train_task1_df = None\n",
    "        self.train_task2_df = None\n",
    "#         self.test_set = None\n",
    "        \n",
    "    \n",
    "    def load_task1(self):\n",
    "        \n",
    "        rows=[]\n",
    "        with open(os.path.join('dontpatronizeme_pcl.tsv')) as f:\n",
    "            for line in f.readlines()[4:]:\n",
    "                par_id=line.strip().split('\\t')[0]\n",
    "                art_id = line.strip().split('\\t')[1]\n",
    "                keyword=line.strip().split('\\t')[2]\n",
    "                country=line.strip().split('\\t')[3]\n",
    "                t=line.strip().split('\\t')[4].lower()\n",
    "                l=line.strip().split('\\t')[-1]\n",
    "                if l=='0' or l=='1':\n",
    "                    lbin=0\n",
    "                else:\n",
    "                    lbin=1\n",
    "                rows.append({'par_id':par_id,\n",
    "                             'art_id':art_id,\n",
    "                             'keyword':keyword,\n",
    "                             'country':country,\n",
    "                             'text':t, \n",
    "                             'label':lbin, \n",
    "                             'orig_label':l\n",
    "                             })\n",
    "                df=pd.DataFrame(rows, columns=['par_id', 'art_id', 'keyword', 'country', 'text', 'label', 'orig_label']) \n",
    "                self.train_task1_df = df\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-YSB6jlXvlGO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "A=DontPatronizeMe()\n",
    "data=A.load_task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "PWByNh2IvlCz",
    "outputId": "e134ea22-6785-4c1c-b54c-b34122ccdc95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>we 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>migrant</td>\n",
       "      <td>in libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigrant</td>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disabled</td>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>refugee</td>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in-need</td>\n",
       "      <td>to bring down high blood sugar levels , insuli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>refugee</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hopeless</td>\n",
       "      <td>\"\"\" they 're either hopeless for being beaten ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>homeless</td>\n",
       "      <td>nueva era , ilocos norte - no family shall be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in-need</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword                                               text  label\n",
       "0   hopeless  we 're living in times of absolute insanity , ...      0\n",
       "1    migrant  in libya today , there are countless number of...      0\n",
       "2  immigrant  \"white house press secretary sean spicer said ...      0\n",
       "3   disabled  council customers only signs would be displaye...      0\n",
       "4    refugee  \"\"\" just like we received migrants fleeing el ...      0\n",
       "5    in-need  to bring down high blood sugar levels , insuli...      0\n",
       "6    refugee  the european union is making an historic mista...      0\n",
       "7   hopeless  \"\"\" they 're either hopeless for being beaten ...      0\n",
       "8   homeless  nueva era , ilocos norte - no family shall be ...      0\n",
       "9    in-need  his spokesman said the kremlin needed more inf...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['art_id'], axis=1)  # dropping unnecesary column\n",
    "data = data.drop(['par_id'], axis=1)  # dropping unnecesary column\n",
    "data = data.drop(['orig_label'], axis=1)  # dropping unnecesary column\n",
    "data = data.drop(['country'], axis=1)  # dropping unnecesary column\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "7SR0Rmi5vk6o",
    "outputId": "0b0d33ad-1a53-4c31-adfd-7515ccebb122"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to bring down high blood sugar levels , insuli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"\"\" they 're either hopeless for being beaten ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nueva era , ilocos norte - no family shall be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  we 're living in times of absolute insanity , ...      0\n",
       "1  in libya today , there are countless number of...      0\n",
       "2  \"white house press secretary sean spicer said ...      0\n",
       "3  council customers only signs would be displaye...      0\n",
       "4  \"\"\" just like we received migrants fleeing el ...      0\n",
       "5  to bring down high blood sugar levels , insuli...      0\n",
       "6  the european union is making an historic mista...      0\n",
       "7  \"\"\" they 're either hopeless for being beaten ...      0\n",
       "8  nueva era , ilocos norte - no family shall be ...      0\n",
       "9  his spokesman said the kremlin needed more inf...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['keyword'], axis=1)  # dropping unnecesary column\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "x0aA_Rvmvjwn",
    "outputId": "915542d0-cefd-48db-b47f-4ee456ae71cd"
   },
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "data = data.sample(frac = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VSXhbBvwiSW"
   },
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "train = data[0:int(n*0.7)]\n",
    "validation = data[int(n*0.7):int(n*0.9)]\n",
    "test = data[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxouPYwFQnJT",
    "outputId": "c345c445-0535-4e22-c4eb-ba1e71b1cfd6"
   },
   "outputs": [],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZTYGJlnwieq",
    "outputId": "8d1f72a7-ef1e-41b7-8eb8-d5aa87e54c45"
   },
   "outputs": [],
   "source": [
    "train.shape , validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIQgpdnOwijc",
    "outputId": "4052cb49-4c74-4fad-aa97-4a9895516b8d"
   },
   "outputs": [],
   "source": [
    "train['text'].apply(lambda x:len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-mT01TIwipS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2thNJcYKvQ8x"
   },
   "outputs": [],
   "source": [
    "# #Load the set\n",
    "# train_df=pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "4P76QcF8vQ8x",
    "outputId": "032df50f-34b5-47f5-d21c-e4e51621a50d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing,metrics,manifold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,cross_val_predict\n",
    "from imblearn.over_sampling import ADASYN,SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "import collections\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import xgboost\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import classification_report,roc_auc_score,roc_curve,r2_score,recall_score,confusion_matrix,precision_recall_curve\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,StratifiedShuffleSplit\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD,SparsePCA\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud,STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import classification_report,roc_auc_score,roc_curve,r2_score,recall_score,confusion_matrix,precision_recall_curve\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,StratifiedShuffleSplit\n",
    "from xgboost import XGBClassifier as xg\n",
    "#from lightgbm import LGBMClassifier as lg\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HAjnbEGvQ8y",
    "outputId": "76bbb6c0-58fa-4737-a630-1df57410cd86"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# #Convert the labels into integers (numerics) for reference.\n",
    "\n",
    "# train_li=[]\n",
    "# for i in range(len(train_df)):\n",
    "#     if (train[''][i]=='positive'):\n",
    "#         train_li.append(1)\n",
    "#     else:\n",
    "#         train_li.append(0)\n",
    "# train_df['Binary']=train_li\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XG-Q5kJvQ8y",
    "outputId": "05419cf6-3a59-48c0-8177-7257d92ed464"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Running the Preprocessing and cleaning phase as well as the TFIDF Vectorization\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import re\n",
    "#Removes Punctuations\n",
    "def remove_punctuations(data):\n",
    "    punct_tag=re.compile(r'[^\\w\\s]')\n",
    "    data=punct_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes HTML syntaxes\n",
    "def remove_html(data):\n",
    "    html_tag=re.compile(r'<.*?>')\n",
    "    data=html_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes URL data\n",
    "def remove_url(data):\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes Emojis\n",
    "def remove_emoji(data):\n",
    "    emoji_clean= re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    data=emoji_clean.sub(r'',data)\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "#Lemmatize the corpus\n",
    "def lemma_traincorpus(data):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    out_data=\"\"\n",
    "    for words in data:\n",
    "        out_data+= lemmatizer.lemmatize(words)\n",
    "    return out_data\n",
    "\n",
    "def tfidf(data):\n",
    "    tfidfv = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)\n",
    "    fit_data_tfidf=tfidfv.fit_transform(data)\n",
    "    return fit_data_tfidf\n",
    "\n",
    "\n",
    "train['text']=train['text'].apply(lambda z: remove_punctuations(z))\n",
    "train['text']=train['text'].apply(lambda z: remove_html(z))\n",
    "train['text']=train['text'].apply(lambda z: remove_url(z))\n",
    "train['text']=train['text'].apply(lambda z: remove_emoji(z))\n",
    "count_good=train[train['label']==0]\n",
    "count_bad=train[train['label']==1]\n",
    "train['text']=train['text'].apply(lambda z: lemma_traincorpus(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PziCYrwcvQ8y"
   },
   "source": [
    "## Standard Neural Networks with Static Semantic Embeddings Baseline\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/688/1*zR61FG9RUd6ul4ecXA_euQ.jpeg\">\n",
    "\n",
    "\n",
    "In this context, we will be building a preliminary deep model using sophisticated neural networks and variants of RNNs. We will be building a simple LSTM model for validating the influence of deep models with respect to the statistical ones. In the first case, we will be using the Keras Embedding layer and visualize the results before using the embedding models.\n",
    "\n",
    "[Keras LSTM](https://keras.io/api/layers/recurrent_layers/lstm/)\n",
    "[Keras](https://keras.io/)\n",
    "[Keras Starter Guides](https://keras.io/examples/nlp/)\n",
    "[Tensorflow Starter](https://www.tensorflow.org/tutorials/keras/text_classification)\n",
    "[Tensorflow Hub](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub)\n",
    "[Jason's Blog-Best practises](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/)\n",
    "[Jason's Blog-Convolution Networks](https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/)\n",
    "\n",
    "\n",
    "More resources will be provided, and for now we will be focussing on creating specific  RNN (Recurrent Neural Variants) with/without Static Semantic Embeddings to create a Neural Model Baseline. \n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/875/1*n-IgHZM5baBUjq0T7RYDBw.gif\">\n",
    "\n",
    "\n",
    "### Recurrent Neural Networks\n",
    "\n",
    "Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language.\n",
    "\n",
    "Schematically, a RNN layer uses a for loop to iterate over the timesteps of a sequence, while maintaining an internal state that encodes information about the timesteps it has seen so far.\n",
    "\n",
    "The Keras RNN API is designed with a focus on:\n",
    "\n",
    "- Ease of use: the built-in keras.layers.RNN, keras.layers.LSTM, keras.layers.GRU layers enable you to quickly build recurrent models without having to make difficult configuration choices.\n",
    "\n",
    "- Ease of customization: You can also define your own RNN cell layer (the inner part of the for loop) with custom behavior, and use it with the generic keras.layers.RNN layer (the for loop itself). This allows you to quickly prototype different research ideas in a flexible way with minimal code.\n",
    "\n",
    "\n",
    "A classic RNN appears as follows:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/627/1*go8PHsPNbbV6qRiwpUQ5BQ.png\">\n",
    "\n",
    "This [video](https://youtu.be/8HyCNIVRbSU) provides a good description of how RNNs work.\n",
    "\n",
    "\n",
    "Particulary a RNN works on the logic:\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/875/1*3mDe6V5DRXqpHYKDfxN4Rg.png\">\n",
    "\n",
    "\n",
    "There are various kinds of such networks:\n",
    "\n",
    "\n",
    "- Encoding Recurrent Neural Networks are just folds. They’re often used to allow a neural network to take a variable length list as input, for example taking a sentence as input.\n",
    "\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-encoding.png\">\n",
    "\n",
    "\n",
    "- Generating Recurrent Neural Networks are just unfolds. They’re often used to allow a neural network to produce a list of outputs, such as words in a sentence.\n",
    "\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-generating.png\">\n",
    "\n",
    "\n",
    "- General Recurrent Neural Networks are accumulating maps. They’re often used when we’re trying to make predictions in a sequence. For example, in voice recognition, we might wish to predict a phenome for every time step in an audio segment, based on past context.\n",
    "\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-general.png\">\n",
    "\n",
    "\n",
    "- Bidirectional Recursive Neural Networks are a more obscure variant, which I mention primarily for flavor. In functional programming terms, they are a left and a right accumulating map zipped together. They’re used to make predictions over a sequence with both past and future context.\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-bidirectional.png\">\n",
    "\n",
    " \n",
    " \n",
    "Some resources for understanding the derivatives and optimization inside the RNNs:\n",
    "\n",
    "- [Maths](https://www.cs.toronto.edu/~tingwuwang/rnn_tutorial.pdf)\n",
    "- [Blog](https://colah.github.io/posts/2015-09-NN-Types-FP/)\n",
    "- [Blog](https://towardsdatascience.com/under-the-hood-of-neural-networks-part-2-recurrent-af091247ba78)\n",
    "- [Kernel](https://www.kaggle.com/abhilash1910/nlp-workshop-ml-india#Neural-Networks)\n",
    "\n",
    "\n",
    "These are some starter resources for creating preliminary networks for sentiment analysis, text/intent classifications. There will be some advanced architectures which will be focussed later.\n",
    "\n",
    "\n",
    "### Long Short Term Memory (LSTM)\n",
    "\n",
    "[Drawbacks of RNNS](https://colah.github.io/posts/2015-08-Understanding-LSTMs/): One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they’d be extremely useful. But can they? It depends.Sometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in “the clouds are in the sky,” we don’t need any further context – it’s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.But there are also cases where we need more context. Consider trying to predict the last word in the text “I grew up in France… I speak fluent French.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.\n",
    "Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.In theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by Hochreiter (1991) [German] and Bengio, et al. (1994), who found some pretty fundamental reasons why it might be difficult.\n",
    "Thankfully, LSTMs don’t have this problem!\n",
    "\n",
    "- LSTMs:\n",
    " \n",
    " <img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\">\n",
    " \n",
    " The first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “forget gate layer.” It looks at ```ht−1``` and ```xt```, and outputs a number between 0 and 1 for each number in the cell state ```Ct−1```. A 1 represents “completely keep this” while a 0 represents “completely get rid of this.”\n",
    "\n",
    "Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png\">\n",
    "\n",
    "\n",
    "The next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a sigmoid layer called the “input gate layer” decides which values we’ll update. Next, a tanh layer creates a vector of new candidate values, ```C~t```, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.\n",
    "\n",
    "In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png\">\n",
    "\n",
    "It’s now time to update the old cell state, ```Ct−1```, into the new cell state ```Ct```. The previous steps already decided what to do, we just need to actually do it.\n",
    "\n",
    "We multiply the old state by ```ft```, forgetting the things we decided to forget earlier. Then we add ```it∗C~t```. This is the new candidate values, scaled by how much we decided to update each state value.\n",
    "\n",
    "In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png\">\n",
    "\n",
    "Finally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n",
    "\n",
    "For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png\">\n",
    "\n",
    "\n",
    "An illustrated working of the LSTM is provided:\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1900/1*GjehOa513_BgpDDP6Vkw2Q.gif\">\n",
    "\n",
    "\n",
    "Some blogs:\n",
    "\n",
    "- [Blog](https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fillustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21&psig=AOvVaw3GJ2-g9jyCgtlUxlTAmyJ8&ust=1608535825759000&source=images&cd=vfe&ved=0CA0QjhxqFwoTCLjax4eF3O0CFQAAAAAdAAAAABAD)\n",
    "- [Blog](https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/)\n",
    "- [Blog](https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/)\n",
    "- [Paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf)\n",
    "\n",
    "There are several Variants of LSTMs some of the most famous being Depth GRU /Gated Recurrent Units:\n",
    "\n",
    "A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by Cho, et al. (2014). It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.\n",
    "\n",
    "<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ0VShPwvQ8z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM, Dense,Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import keras.backend as k\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional,GRU\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkElLrhbvQ80"
   },
   "source": [
    "### Creating a Basic LSTM Neural Model without Embeddings\n",
    "\n",
    "In this case, we will not be using an y pretrained static/dynamic embeddings but will be using a simple Neural Network model of LSTM to create our network.The steps are as follows:\n",
    "\n",
    "\n",
    "- Tokenize the input data (Keras.Preprocessing)\n",
    "- Creating the limits of Maxlen, Max Features and Embedding Size for our Embedding Matrix\n",
    "- Pad the tokenized data to maintain uniformity in length of the input features\n",
    "\n",
    "A more descriptive overview is found [here](https://www.kaggle.com/abhilash1910/nlp-workshop-ml-india#Neural-Networks) . This also provides an [idea](https://www.tensorflow.org/guide/keras/rnn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_uloqxFvQ80",
    "outputId": "fb7330fd-f3cb-400e-a2b0-c34b19d9c0ca"
   },
   "outputs": [],
   "source": [
    "##First Step is to test model performance without pretrained Embeddings\n",
    "## Will be using only Keras Embeddings in this case with a minimal neural network model\n",
    "\n",
    "maxlen=1000\n",
    "max_features=5000 \n",
    "embed_size=300\n",
    "\n",
    "#clean some null words or use the previously cleaned & lemmatized corpus\n",
    "\n",
    "train_y=train['label']\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwhjhIENvQ80"
   },
   "source": [
    "## Creating the Model architecture\n",
    "\n",
    "Here we creating a [sequential model](https://keras.io/api/models/sequential/) and the embedding always has to be the first layer for our use case. In any neural model, Embedding layer always comes first followed by other layers- LSTM/GRU and others. The heirarchy of the model can be represented as below:\n",
    "\n",
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs12859-019-3079-8/MediaObjects/12859_2019_3079_Fig2_HTML.png\">\n",
    "\n",
    "\n",
    "A proper model overview comprising of LSTMs and Embeddings is provided here:\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/6ac8328113639044d2beb83246b9d07f513ac6c8/3-Figure1-1.png\">\n",
    "\n",
    "Some resources:\n",
    "\n",
    "- [Kernels](https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer)\n",
    "- [Kernels](https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sc2y08vlvQ81",
    "outputId": "c3bd09b6-8df5-4f2b-ab0c-942351c8016e"
   },
   "outputs": [],
   "source": [
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features,embed_size,input_length=maxlen))\n",
    "model.add(LSTM(60))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file=\"simple_model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")\n",
    "model.fit(train_x,train_y,batch_size=512,epochs=3,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bml7LnZcvQ81"
   },
   "source": [
    "## Model Visualization\n",
    "\n",
    "The model with its individual layers can be visualized as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/qI6zRqM.png\">\n",
    "\n",
    "\n",
    "We can also look into the model parameters and the weights of the intermediate layers. We can visualize the sizes of the hidden layers and the output of each sequential layer in the model. Some resources:\n",
    "\n",
    "- [Keras](https://keras.io/getting_started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction)\n",
    "- [Stack Overflow](https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer)\n",
    "- [Kite](https://www.kite.com/python/answers/how-to-get-the-output-of-each-layer-of-a-keras-model-in-python#:~:text=A%20Keras%20model%20runs%20data,and%20applies%20the%20layer%20funtion.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SMhYh87vQ81",
    "outputId": "0f851a16-a7b0-4447-dcd2-5b9c23b0aba0"
   },
   "outputs": [],
   "source": [
    "## Get to know individual layer sizes and parameters \n",
    "\n",
    "from keras import backend as k\n",
    "inputs=model.input\n",
    "outputs=[layer.output for layer in model.layers]\n",
    "print(f\"Outputs of the sequential layers{outputs}\")\n",
    "functions=[k.function([inputs],[outs]) for outs in outputs]\n",
    "print(f'Sequential Model Layers{functions}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj-_FxhQvQ82",
    "outputId": "e9296c8f-bb62-4993-b6c1-8fede23d9567"
   },
   "outputs": [],
   "source": [
    "#Fit and validate\n",
    "model.fit(train_x,train_y,batch_size=128,epochs=3,verbose=2,validation_data=(val_x,val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMYggnEUvQ82"
   },
   "source": [
    "## Build a Static Semantic Embedding Neural Network(LSTM) Baseline\n",
    "\n",
    "In this case, we will be using pretrained embeddings for ouruse case. For this we will be using the embedding matrix creation  code from our [previous Notebook](https://www.kaggle.com/colearninglounge/nlp-end-to-end-cll-nlp-workshop).\n",
    "\n",
    "Particularly this lines of code:\n",
    "\n",
    "```python\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "maxlen=1000\n",
    "max_features=5000 \n",
    "embed_size=300\n",
    "\n",
    "train_sample=train_df['review']\n",
    "\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_sample))\n",
    "train_sample=tokenizer.texts_to_sequences(train_sample)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_sample=pad_sequences(train_sample,maxlen=maxlen)\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_FILE = '../input/wikinews300d1msubwordvec/wiki-news-300d-1M-subword.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "plt.plot(embedding_matrix[20])\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqdLdbrp72cj",
    "outputId": "e3ebf77e-b48f-49fe-f14b-14ae2a6a734f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOHe8PoGft91",
    "outputId": "284ce562-263b-47b1-b967-61ddf6a205e6"
   },
   "outputs": [],
   "source": [
    "! pip install kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQoCb1cIgIS4",
    "outputId": "756b2c3f-231e-4743-bc6e-ce35afdea091"
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download takuok/glove840b300dtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QNFAAv7gIQw",
    "outputId": "85fe86dd-977b-40fe-8759-48d0833b06de"
   },
   "outputs": [],
   "source": [
    "! unzip glove840b300dtxt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zI5stdjvQ82",
    "outputId": "ef6155d9-7074-4f4c-9fe5-d5b4ec71ab22"
   },
   "outputs": [],
   "source": [
    "##Build Static Embedding on top of a Neural Model\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "maxlen=1000\n",
    "max_features=5000 \n",
    "embed_size=300\n",
    "\n",
    "train_sample=train['text']\n",
    "\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_sample))\n",
    "train_sample=tokenizer.texts_to_sequences(train_sample)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_sample=pad_sequences(train_sample,maxlen=maxlen)\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_FILE = 'glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHnsDHj3vQ82"
   },
   "source": [
    "## Run the same model with the Pretrained Embeddings\n",
    "\n",
    "Now we will run the same model as before with the pretrained static embeddings- Glove in our use case. I have trained it for 2 epochs but this can be made to train on an even larger epoch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbFDvM5xvQ82",
    "outputId": "7663d7e6-aba0-422e-806b-15207ad28376"
   },
   "outputs": [],
   "source": [
    "inp=Input(shape=(maxlen,))\n",
    "z=Embedding(max_features,embed_size,weights=[embedding_matrix])(inp)\n",
    "z=Bidirectional(LSTM(60,return_sequences='True'))(z)\n",
    "z=GlobalMaxPool1D()(z)\n",
    "z=Dense(16,activation='relu')(z)\n",
    "z=Dense(1,activation='sigmoid')(z)\n",
    "model=Model(inputs=inp,outputs=z)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file=\"glove_simple_model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")\n",
    "\n",
    "model.fit(train_x,train_y,batch_size=128,epochs=3,verbose=2,validation_data=(val_x,val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4jFF5y-vQ83"
   },
   "source": [
    "## Model Visualization\n",
    "\n",
    "The Simple LSTM Model with Glove Pretrained embeddings:\n",
    "\n",
    "<img src=\"https://i.imgur.com/7FpjJVP.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3alINk89vQ84"
   },
   "source": [
    "## Encoder Decoder Architectures\n",
    "\n",
    "[Encoder-Decoders](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) is a classic architecture mostly popular for sequence2sequence learning. Encoder-Decoders are most popularly used for neural machine translation (seq2seq learning with attention). The general workflow revolves around stacks of RNNs (LSTMs/GRUs/TimeDistributed Cells) which behaves as an encoder takes as input 3 parameters (max_features,embed_size,maxlen in our example) and returns an output. We then save the 2 output LSTM cell states ,the h and c states. We design the decoder model in a similar manner (if the internal layers are modified it becomes a hybrid decoder). And while passing the inputs of the decoder, we also pass the 2 output LSTM cell states from the encoder output (namely the h and c states). The output of the decoder is then passed through a activation/distribution function to optimize our target loss function.\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/875/1*CkeGXClZ5Xs0MhBc7xFqSA.png\">\n",
    "\n",
    "\n",
    "\n",
    "### Descriptive overview of NMT with Encoder Decoders:\n",
    "\n",
    "\n",
    "\n",
    "In the context of NMT, the words of one language should be mapped to a different language (machine translation). An example of such an architecture is as follows:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://blog.keras.io/img/seq2seq/seq2seq-teacher-forcing.png\">\n",
    "\n",
    "\n",
    "\n",
    "In the general case, input sequences and output sequences have different lengths (e.g. machine translation) and the entire input sequence is required in order to start predicting the target. This requires a more advanced setup, which is what people commonly refer to when mentioning \"sequence to sequence models\" with no further context. Here's how it works:\n",
    "\n",
    "- A RNN layer (or stack thereof) acts as \"encoder\": it processes the input sequence and returns its own internal state. Note that we discard the outputs of the encoder RNN, only recovering the state. This state will serve as the \"context\", or \"conditioning\", of the decoder in the next step.\n",
    "\n",
    "- Another RNN layer (or stack thereof) acts as \"decoder\": it is trained to predict the next characters of the target sequence, given previous characters of the target sequence. Specifically, it is trained to turn the target sequences into the same sequences but offset by one timestep in the future, a training process called \"teacher forcing\" in this context. Importantly, the encoder uses as initial state the state vectors from the encoder, which is how the decoder obtains information about what it is supposed to generate. Effectively, the decoder learns to generate targets[t+1...] given targets[...t], conditioned on the input sequence.\n",
    "\n",
    "\n",
    "\n",
    "### Pictorial Representation of Encoder-Decoders for Generative Modelling\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1250/1*LYGO4IxqUYftFdAccg5fVQ.png\">\n",
    "\n",
    "\n",
    "\n",
    "Some resources:\n",
    "\n",
    "- [TF-Blog](https://www.tensorflow.org/tutorials/text/nmt_with_attention)\n",
    "- [Blog](https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639)\n",
    "- [Blog](https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtYPb_2BvQ84",
    "outputId": "e99fb08f-9621-4666-ff2d-fe9247909c5e"
   },
   "outputs": [],
   "source": [
    "maxlen=1000\n",
    "max_features=5000 \n",
    "embed_size=300\n",
    "#clean some null words or use the previously cleaned & lemmatized corpus\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_y= LabelEncoder()\n",
    "labels=label_y.fit_transform(train['label'])\n",
    "labels\n",
    "train_y=labels\n",
    "\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)\n",
    "#sequence to sequence basic lstm encoder decoders\n",
    "def seq2seq_encoder_decoder(maxlen,max_features,embed_size):\n",
    "    #Creating LSTM  encoder neural model with no pretrained embeddings\n",
    "    encoder_inp=Input(shape=(maxlen,))\n",
    "    encoder_embed=Embedding(max_features,embed_size,input_length=maxlen,trainable=True)(encoder_inp)\n",
    "    encoder_lstm_cell=LSTM(60,return_state='True')\n",
    "    encoder_outputs,encoder_state_lstm_h,encoder_state_lstm_c=encoder_lstm_cell(encoder_embed)\n",
    "    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n",
    "    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n",
    "    decoder_inp=Input(shape=(maxlen,))\n",
    "    decoder_embed=Embedding(max_features,embed_size,input_length=maxlen,trainable=True)(decoder_inp)\n",
    "    decoder_lstm_cell=LSTM(60,return_sequences='True',return_state=True)\n",
    "    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[encoder_state_lstm_h,encoder_state_lstm_c])\n",
    "    decoder_dense_cell=Dense(16,activation='relu')\n",
    "    decoder_d_output=decoder_dense_cell(decoder_outputs)\n",
    "    decoder_dense_cell2=Dense(1,activation='sigmoid')\n",
    "    decoder_output=decoder_dense_cell2(decoder_d_output)\n",
    "    model=Model([encoder_inp,decoder_inp],decoder_output)\n",
    "    print(encoder_embed.shape)\n",
    "    model.summary()\n",
    "    return model        \n",
    "model=seq2seq_encoder_decoder(maxlen,max_features,embed_size)  \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(\n",
    "    model,to_file=\"seq2seq_encoder_decoder_model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96)\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "test_y = np.asarray(test_y).astype('float32').reshape((-1,1))\n",
    "model.fit([train_x,train_x],train_y,batch_size=512,epochs=3,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4UwOELnJ9S9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wynT2jFZvQ86"
   },
   "source": [
    "##  Encoder Decoder With Attention\n",
    "\n",
    "This section will comprise of Hybrid Encoder Decoder Architectures with variants of Attention Mechanisms. For an introduction attention refers to allowing certain neural weights to be focussed during training and this in turn assists in model performance.\n",
    "\n",
    "The main paper behind this is [Attention is all you need](https://paperswithcode.com/paper/attention-is-all-you-need)\n",
    "A preview of this is provided in the images below:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\">\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\">\n",
    "\n",
    "\n",
    "More details will be explained soon on the different variants . For now, this tf resource should [help](https://www.tensorflow.org/tutorials/text/nmt_with_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O993H6-rvQ86",
    "outputId": "caaf2073-cde4-40b5-ca76-5f251c0e6706"
   },
   "outputs": [],
   "source": [
    "#Bidirectional LSTM Encoder-Decoder\n",
    "# maxlen=1000\n",
    "# max_features=5000 \n",
    "# embed_size=300\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_y= LabelEncoder()\n",
    "labels=label_y.fit_transform(train['label'])\n",
    "labels\n",
    "train_y=labels\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)\n",
    "\n",
    "def seq2seq_encoder_decoder_glove_bilstm_hybrid(maxlen,max_features,embedding_matrix):\n",
    "    #Creating LSTM  encoder neural model with no pretrained embeddings\n",
    "    encoder_inp=Input(shape=(maxlen,))\n",
    "    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n",
    "    encoder_lstm_cell=Bidirectional(LSTM(60,return_state='True'),merge_mode='sum')\n",
    "    encoder_outputs,encoder_state_flstm_h,encoder_state_flstm_c,encoder_state_blstm_h,encoder_state_blstm_c=encoder_lstm_cell(encoder_embed)\n",
    "    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n",
    "    encoded_states=[encoder_state_flstm_h+encoder_state_blstm_h,encoder_state_flstm_c+encoder_state_blstm_c]\n",
    "    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n",
    "    decoder_inp=Input(shape=(maxlen,))\n",
    "    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n",
    "    decoder_lstm_cell=LSTM(60,return_sequences='True',return_state=True)\n",
    "    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n",
    "#     decoderoutputs,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n",
    "    decoder_dense_cell=Dense(16,activation='relu')\n",
    "    decoder_d_output=decoder_dense_cell(decoder_outputs)\n",
    "    decoder_dense_cell2=Dense(1,activation='sigmoid')\n",
    "    decoder_output=decoder_dense_cell2(decoder_d_output)\n",
    "    model=Model([encoder_inp,decoder_inp],decoder_output)\n",
    "    model.summary()\n",
    "    return model        \n",
    "model=seq2seq_encoder_decoder_glove_bilstm_hybrid(maxlen,max_features,embedding_matrix)  \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(model,to_file=\"seq2seq_encoder_decoder_model_glove_bilstm_hybrid.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96)\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "test_y = np.asarray(test_y).astype('float32').reshape((-1,1))  \n",
    "model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1_GW2SvQ86"
   },
   "source": [
    "## Encoder Decoder Model With Bahdanau Attention\n",
    "\n",
    "The model architecture is as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/lIMEt59.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aL7hJDEhvQ86",
    "outputId": "428a920c-a56c-4d35-bf58-7774cdfbf0d2"
   },
   "outputs": [],
   "source": [
    "# import MiniAttention.MiniAttention as ma\n",
    "train_y=labels\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "class Simple_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(Simple_Attention,self).__init__()\n",
    "        self.units=units\n",
    "        self.Wq=tf.keras.layers.Dense(self.units)\n",
    "        self.Wk=tf.keras.layers.Dense(self.units)\n",
    "        self.Wv=tf.keras.layers.Dense(60)\n",
    "        \n",
    "    def call(self,q,v):\n",
    "        self.q=q\n",
    "        self.v=v\n",
    "#         print(self.q.shape)\n",
    "        q_t=tf.expand_dims(self.q,1)\n",
    "        score=self.Wv(tf.nn.tanh(self.Wq(self.q)+self.Wk(self.v)))\n",
    "        attention_wts=tf.nn.softmax(score,axis=1)\n",
    "#         print(attention_wts.shape)\n",
    "        context_vector=(attention_wts*self.v)\n",
    "#         context_vector=tf.reduce_sum(context_vector,axis=1)\n",
    "#         print(context_vector.shape)\n",
    "        return context_vector,attention_wts\n",
    "    \n",
    "\n",
    "        \n",
    "def seq2seq_encoder_decoder_glove_bilstm_hybrid_bahdanau(maxlen,max_features,embedding_matrix):\n",
    "    #Creating LSTM  encoder neural model with no pretrained embeddings\n",
    "    encoder_inp=Input(shape=(maxlen,))\n",
    "    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n",
    "#     encoder_embed_attention=ma.MiniAttentionBlock(None,None,None,keras.regularizers.L2(l2=0.02),None,None,None,None,None)(encoder_embed)\n",
    "    encoder_lstm_cell=LSTM(60,return_state='True')\n",
    "    encoder_outputs,encoder_state_flstm_h,encoder_state_flstm_c=encoder_lstm_cell(encoder_embed)\n",
    "    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n",
    "    encoded_states=[encoder_state_flstm_h,encoder_state_flstm_c]\n",
    "    \n",
    "    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n",
    "    decoder_inp=Input(shape=(maxlen,))\n",
    "    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n",
    "    bahdanau_attention=Simple_Attention(60)\n",
    "    \n",
    "    decoder_embed_attention_h,decoder_embed_wghts_h=bahdanau_attention(encoder_state_flstm_h,encoder_outputs)\n",
    "    decoder_embed_attention_c,decoder_embed_wghts_c=bahdanau_attention(encoder_state_flstm_c,encoder_outputs)\n",
    "#     print(decoder_embed_wghts)\n",
    "    decoder_lstm_cell=LSTM(60,return_sequences='True',return_state=True)\n",
    "    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[decoder_embed_wghts_h,decoder_embed_wghts_c])\n",
    "#     decoderoutputs,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n",
    "    \n",
    "    decoder_dense_cell=Dense(16,activation='relu')\n",
    "    decoder_d_output=decoder_dense_cell(decoder_outputs)\n",
    "    decoder_dense_cell2=Dense(1,activation='sigmoid')\n",
    "    decoder_output=decoder_dense_cell2(decoder_d_output)\n",
    "    model=Model([encoder_inp,decoder_inp],decoder_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "model=seq2seq_encoder_decoder_glove_bilstm_hybrid_bahdanau(maxlen,max_features,embedding_matrix)  \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(\n",
    "    model,to_file=\"seq2seq_encoder_decoder_model_glove_bilstm_bahdanau_attention.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96)\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "test_y = np.asarray(test_y).astype('float32').reshape((-1,1)) \n",
    "model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs4UXdh6vQ87"
   },
   "source": [
    "## Encoder Decoder With Luong Attention\n",
    "\n",
    "In this case, we are  going to replicate the training process with [Luong Dot Product (Multiplicative Style) Attention Mechanism](https://arxiv.org/abs/1508.04025).\n",
    "\n",
    "\n",
    "### Global Attention\n",
    "\n",
    "\n",
    "<img  src=\"https://miro.medium.com/max/626/1*LhEapXF1mtaB3rDgIjcceg.png\">\n",
    "\n",
    "\n",
    "Luong, et al., 2015 proposed the “global” and “local” attention. The global attention is similar to the soft attention, while the local one is an interesting blend between hard and soft, an improvement over the hard attention to make it differentiable: the model first predicts a single aligned position for the current target word and a window centered around the source position is then used to compute a context vector.\n",
    "\n",
    "The commonality between Global and Local attention\n",
    "\n",
    "- At each time step t, in the decoding phase, both approaches, global and local attention, first take the hidden state hₜ at the top layer of a stacking LSTM as an input.\n",
    "- The goal of both approaches is to derive a context vector 𝒸ₜ to capture relevant source-side information to help predict the current target word yₜ\n",
    "- Attentional vectors are fed as inputs to the next time steps to inform the model about past alignment decisions.\n",
    "- Global and local attention models differ in how the context vector 𝒸ₜ is derived\n",
    "- Before we discuss the global and local attention, let’s understand the conventions used by Luong’s attention mechanism for any given time t\n",
    "  - 𝒸ₜ : context vector\n",
    "  - aₜ : alignment vector\n",
    "  - hₜ : current target hidden state\n",
    "  - hₛ : current source hidden state\n",
    "  - yₜ: predicted current target word\n",
    "  - h˜ₜ : Attentional vectors\n",
    "\n",
    "- The global attentional model considers all the hidden states of the encoder when calculating the context vector 𝒸ₜ.\n",
    "- A variable-length alignment vector aₜ equal to the size of the number of time steps in the source sequence is derived by comparing the current target hidden state hₜ with each of the source hidden state hₛ\n",
    "- The alignment score is referred to as a content-based function for which we consider three different alternatives\n",
    "\n",
    "\n",
    "### Local Attention\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/538/1*YXjdGl3CnSfHfzYpQiObgg.png\">\n",
    "\n",
    "\n",
    "- Local attention only focuses on a small subset of source positions per target words unlike the entire source sequence as in global attention\n",
    "- Computationally less expensive than global attention\n",
    "- The local attention model first generates an aligned position Pₜ for each target word at time t.\n",
    "- The context vector 𝒸ₜ is derived as a weighted average over the set of source hidden states within selected the window\n",
    "- The aligned position can be monotonically or predictively selected\n",
    "\n",
    "\n",
    "### Formula \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/875/1*_Ta67S8_lXTbVzJMztkxKg.png\">\n",
    "\n",
    "\n",
    "Some resources:\n",
    "\n",
    "- [Lilan's Blog](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#:~:text=Self%2Dattention%2C%20also%20known%20as,summarization%2C%20or%20image%20description%20generation.)\n",
    "- [Paper](https://arxiv.org/pdf/1508.04025.pdf)\n",
    "- [Paper](https://arxiv.org/pdf/1508.04025.pdf)\n",
    "- [Paper](https://arxiv.org/pdf/1508.4025.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdfoW3XevQ87"
   },
   "source": [
    "## Encoder Decoder Model Architecture with Luong Attention\n",
    "\n",
    "The architecture is as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/ZAJ2iTH.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAHsCeXxvQ87",
    "outputId": "ea14f6ab-09b7-48d0-d694-e59953c85ea1"
   },
   "outputs": [],
   "source": [
    "# import MiniAttention.MiniAttention as ma\n",
    "train_y=labels\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Luong_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(Luong_Attention,self).__init__()\n",
    "        self.units=units\n",
    "        self.Wq=tf.keras.layers.Dense(self.units)\n",
    "        self.Wk=tf.keras.layers.Dense(self.units)\n",
    "        self.Wv=tf.keras.layers.Dense(60)\n",
    "        \n",
    "    def call(self,q,v):\n",
    "        self.q=q\n",
    "        self.v=v\n",
    "#         print(self.q.shape)\n",
    "        q_t=tf.expand_dims(self.q,1)\n",
    "#         self.q=tf.transpose(self.q)\n",
    "        score=(self.q)*(self.v)\n",
    "        attention_wts=tf.nn.softmax(score,axis=1)\n",
    "#         print(attention_wts.shape)\n",
    "        context_vector=(attention_wts*self.v)\n",
    "#         context_vector=tf.reduce_sum(context_vector,axis=1)\n",
    "#         print(context_vector.shape)\n",
    "        return context_vector,attention_wts\n",
    "    \n",
    "\n",
    "        \n",
    "def seq2seq_encoder_decoder_glove_bilstm_hybrid_luong(maxlen,max_features,embedding_matrix):\n",
    "    #Creating LSTM  encoder neural model with no pretrained embeddings\n",
    "    encoder_inp=Input(shape=(maxlen,))\n",
    "    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n",
    "#     encoder_embed_attention=ma.MiniAttentionBlock(None,None,None,keras.regularizers.L2(l2=0.02),None,None,None,None,None)(encoder_embed)\n",
    "    encoder_lstm_cell=LSTM(60,return_state='True')\n",
    "    encoder_outputs,encoder_state_flstm_h,encoder_state_flstm_c=encoder_lstm_cell(encoder_embed)\n",
    "    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n",
    "    encoded_states=[encoder_state_flstm_h,encoder_state_flstm_c]\n",
    "    \n",
    "    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n",
    "    decoder_inp=Input(shape=(maxlen,))\n",
    "    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n",
    "    luong_attention=Luong_Attention(128)\n",
    "    \n",
    "    decoder_embed_attention_h,decoder_embed_wghts_h=luong_attention(encoder_state_flstm_h,encoder_outputs)\n",
    "    decoder_embed_attention_c,decoder_embed_wghts_c=luong_attention(encoder_state_flstm_c,encoder_outputs)\n",
    "#     print(decoder_embed_wghts)\n",
    "    decoder_lstm_cell=LSTM(60,return_sequences='True',return_state=True)\n",
    "    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[decoder_embed_wghts_h,decoder_embed_wghts_c])\n",
    "#     decoderoutputs,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n",
    "    \n",
    "    decoder_dense_cell=Dense(16,activation='relu')\n",
    "    decoder_d_output=decoder_dense_cell(decoder_outputs)\n",
    "    decoder_dense_cell2=Dense(1,activation='sigmoid')\n",
    "    decoder_output=decoder_dense_cell2(decoder_d_output)\n",
    "    model=Model([encoder_inp,decoder_inp],decoder_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "model=seq2seq_encoder_decoder_glove_bilstm_hybrid_luong(maxlen,max_features,embedding_matrix)  \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(\n",
    "    model,to_file=\"seq2seq_encoder_decoder_model_glove_bilstm_luong_attention.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96)\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "test_y = np.asarray(test_y).astype('float32').reshape((-1,1)) \n",
    "model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8OoSPtdvQ88"
   },
   "source": [
    "## Encoder Decoder Model Architecture with Scaled Dot Product Attention\n",
    "\n",
    "The architecture is as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/pBnshbv.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnnuemoFvQ88",
    "outputId": "066a40a3-4fd6-4c9a-a9dc-7b39ae0d4434"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "train_y=labels\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Scaled_Dot_Product_Self_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(Scaled_Dot_Product_Self_Attention,self).__init__()\n",
    "        self.units=units\n",
    "        self.Wq=tf.keras.layers.Dense(self.units)\n",
    "        self.Wk=tf.keras.layers.Dense(self.units)\n",
    "        self.Wv=tf.keras.layers.Dense(60)\n",
    "        \n",
    "    def call(self,q,k,v,n):\n",
    "        self.q=q\n",
    "        self.v=v\n",
    "        self.n=n\n",
    "        self.k=k\n",
    "#         print(self.q.shape)\n",
    "        q_t=tf.expand_dims(self.q,1)\n",
    "#         self.q=tf.transpose(self.q)\n",
    "        score=(self.Wq(self.q)*self.Wk(self.k))/math.sqrt(n)\n",
    "        attention_wts=tf.nn.softmax(score,axis=1)\n",
    "#         print(attention_wts.shape)\n",
    "        context_vector=(attention_wts*self.v)\n",
    "        context_vector=tf.reduce_sum(context_vector,axis=1)\n",
    "#         print(context_vector.shape)\n",
    "        return context_vector,attention_wts\n",
    "    \n",
    "\n",
    "        \n",
    "def seq2seq_encoder_decoder_glove_bilstm_hybrid_scaled_dot_product_self(maxlen,max_features,embedding_matrix):\n",
    "    #Creating LSTM  encoder neural model with no pretrained embeddings\n",
    "    encoder_inp=Input(shape=(maxlen,))\n",
    "    print(embedding_matrix.shape)\n",
    "    encoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(encoder_inp)\n",
    "#     encoder_embed_attention=ma.MiniAttentionBlock(None,None,None,keras.regularizers.L2(l2=0.02),None,None,None,None,None)(encoder_embed)\n",
    "    encoder_lstm_cell=LSTM(60,return_state='True')\n",
    "    encoder_outputs,encoder_state_flstm_h,encoder_state_flstm_c=encoder_lstm_cell(encoder_embed)\n",
    "    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n",
    "    encoded_states=[encoder_state_flstm_h,encoder_state_flstm_c]\n",
    "    \n",
    "    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n",
    "    decoder_inp=Input(shape=(maxlen,))\n",
    "    decoder_embed=Embedding(max_features,embed_size,weights=[embedding_matrix])(decoder_inp)\n",
    "    scaled_dot_product_attention=Scaled_Dot_Product_Self_Attention(60)\n",
    "    \n",
    "    decoder_embed_attention_h,decoder_embed_wghts_h=scaled_dot_product_attention(encoder_state_flstm_h,encoder_state_flstm_h,encoder_outputs,64)\n",
    "    decoder_embed_attention_c,decoder_embed_wghts_c=scaled_dot_product_attention(encoder_state_flstm_c,encoder_state_flstm_c,encoder_outputs,64)\n",
    "#     print(decoder_embed_wghts)\n",
    "    decoder_lstm_cell=LSTM(60,return_sequences='True',return_state=True)\n",
    "    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[decoder_embed_wghts_h,decoder_embed_wghts_c])\n",
    "#     decoderoutputs,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n",
    "    \n",
    "    decoder_dense_cell=Dense(16,activation='relu')\n",
    "    decoder_d_output=decoder_dense_cell(decoder_outputs)\n",
    "    decoder_dense_cell2=Dense(1,activation='sigmoid')\n",
    "    decoder_output=decoder_dense_cell2(decoder_d_output)\n",
    "    model=Model([encoder_inp,decoder_inp],decoder_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "model=seq2seq_encoder_decoder_glove_bilstm_hybrid_scaled_dot_product_self(maxlen,max_features,embedding_matrix)  \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(\n",
    "    model,to_file=\"seq2seq_encoder_decoder_model_glove_bilstm_scaled_dot_self_product_attention.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96)\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "test_y = np.asarray(test_y).astype('float32').reshape((-1,1)) \n",
    "model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jR8bthEvQ89"
   },
   "source": [
    "## Encoder Decoder Model Architecture with Self Attention\n",
    "\n",
    "The architecture is as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/3sdKFMW.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEkByS-ZvQ89"
   },
   "source": [
    "## Encoder-Decoder with BERT Embeddings\n",
    "\n",
    "\n",
    "This is produced from [Google-research](http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf).Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. [Jay's Blog](http://jalammar.github.io/illustrated-transformer/) provide a very good idea of this logic.\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/transformer_self-attention_visualization.png\">\n",
    "\n",
    "\n",
    "Three vectors q,k and v (query,key and value) are taken into consideration for computation of the self attention mechanism.The q,k and v are normally of 64 dimensions.\n",
    "\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/transformer_self_attention_vectors.png\">\n",
    "\n",
    "\n",
    "The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2.\n",
    "\n",
    "\n",
    "<img  src=\"http://jalammar.github.io/images/t/transformer_self_attention_score.png\">\n",
    "\n",
    "\n",
    "The third and forth steps are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.\n",
    "\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/self-attention_softmax.png\">\n",
    "\n",
    "\n",
    "\n",
    "This softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.\n",
    "The fifth step is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).\n",
    "The sixth step is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).\n",
    "\n",
    "\n",
    "<img  src=\"http://jalammar.github.io/images/t/self-attention-output.png\">\n",
    "\n",
    "The cumulative computation can be thought of like this:\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "HywGYr8mr_4m",
    "outputId": "64d25aca-fe80-422c-8988-b34e2de0f507"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "98b20bd85ec3423882b5546569b11c16",
      "0ec8aa70bd61401bb8c9895d220a8f73",
      "da88fa9c0f25458582d83347cd3b03eb",
      "db04127895bb4fbd883b83eedf0b7271",
      "c58e771d11fc4ef48b553525750687d0",
      "c3da562f0cc34b75855f20e7e7ed58e2",
      "a49d617090fd4f6aaf3f6ea15a362a66",
      "6a171f9dd80e40e6a71c2ee616011961",
      "650f590da14d4e42a5eeb8f476a3aa5a",
      "cce54d22ae724427815e2b6652ad851a",
      "3b6f7ac6ac0545de9baab3a7b0f82aac",
      "d7526ff8cc314ea4aadc4d05f839316c",
      "a8233f6477ce45c0a99edccf26aef616",
      "d88617cd89d44cc0a38040325ef3dc20",
      "133ae031a07348a49782f42d87cb6af5",
      "01adab46a2924358b5fab6d9fcc2a778",
      "455a37bd3c704894b78e2a21548733b8",
      "0834e6d2d3af4abc9e32f46f042619de",
      "e1693d2cd5ac424891a448896d3a24b3",
      "df46e11b06f14e72b7dcb6f31e22eb74",
      "e414e0fb10e646148377bdc1d78f3125",
      "6382eac6b2464a6db2664a9f4f7bfe1f",
      "8c1dcb1d2bfd4465b56fdf572de929a4",
      "61925f32545c421d9581c455d76f4cc1",
      "ab47b6b72b9a4bdba3f902b398a29100",
      "5bd94434fefa42e3a5409f7772d97337",
      "c2d1b2d858b04b038171eed62b4af26e",
      "1c5a9d583b5d40918ad696bb28a3888c",
      "72bff3722aa347fd8c5b804191a2e81b",
      "c0ee589694e44cdcb433c51e7bb0ce4a",
      "e8d97e66a60244eba78eafceec0b5fe5",
      "60064c69f71141468f9019ef68ab8c46",
      "c21fb1c2c84149c0bfa9a45f0bb53e9c",
      "74c2e9350ae24df1948734a3a7dc83aa",
      "a3d1bda315fe4492bd2d7ec4186929dc",
      "d160f65533b443e481e20a24442be8e6",
      "d6ebb00bfc904f78a2cee7870f54e6ac",
      "34c9d132f3be4a52a61a269e0c4f87c7",
      "38789e22afbe4954a115a545df74de1e",
      "20ba82462b99450a8f6adc137cdf87d4",
      "d4ebdd2090ad44299f8b1962055fa08e",
      "b0f87cd130f446748a78395c363a695a",
      "e620710096be4553bf1211e4f80b2b39",
      "797e519155264d0a939567006d4f41d4",
      "a86f18b4710a4c58a8a8df2ed69a3198",
      "5d2b3a06693a48bc93fab26a19a5485c",
      "a1977a373ddb4311b89fa8a8bcf2ac72",
      "33bc2d45177a4281954402114bbdd879",
      "fb76c7033911464dbab81df8e2a0bc07",
      "b0b7f0521dc64671a07dbd3cfd716a6d",
      "c1594b8f5603492e8dc657271ab0ccc7",
      "6d23264350ce422d94d165791fa23c2e",
      "c87900a7087b41958925913c41d0c86a",
      "2d70fc5fdbb54419a9fd88259781ee0f",
      "0e4d92ca103b4eefbac988b4697d1a33"
     ]
    },
    "id": "F24V0RgRvQ89",
    "outputId": "914194d4-458b-4236-ae1e-e9b3fc74eb33"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering\n",
    "\n",
    "maxlen=1000\n",
    "embed_size=768\n",
    "max_features=1000\n",
    "train_df=train[:1000]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_y= LabelEncoder()\n",
    "labels=label_y.fit_transform(train['label'])\n",
    "train_y=labels\n",
    "train_x,test_x,train_y,test_y=train_test_split(train['text'],train_y,test_size=0.2,random_state=42)\n",
    "val_x=test_x\n",
    "#Tokenizing steps- must be remembered\n",
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_x))\n",
    "train_x=tokenizer.texts_to_sequences(train_x)\n",
    "val_x=tokenizer.texts_to_sequences(val_x)\n",
    "\n",
    "#Pad the sequence- To allow same length for all vectorized words\n",
    "train_x=pad_sequences(train_x,maxlen=maxlen)\n",
    "val_x=pad_sequences(val_x,maxlen=maxlen)\n",
    "val_y=test_y\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\n",
    "print(\"Target Values Shape\".format(),train_y.shape)\n",
    "print(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\n",
    "print(\"Target Values Shape\".format(),val_y.shape)\n",
    "\n",
    "def build_model(transformer, max_len=maxlen):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    #Replaced from the Embedding+LSTM/CoNN layers\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    return cls_token,sequence_output\n",
    "    \n",
    "\n",
    "\n",
    "class Scaled_Dot_Product_Self_Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(Scaled_Dot_Product_Self_Attention,self).__init__()\n",
    "        self.units=units\n",
    "        self.Wq=tf.keras.layers.Dense(self.units)\n",
    "        self.Wk=tf.keras.layers.Dense(self.units)\n",
    "        self.Wv=tf.keras.layers.Dense(60)\n",
    "        \n",
    "    def call(self,q,k,v,n):\n",
    "        self.q=q\n",
    "        self.v=v\n",
    "        self.n=n\n",
    "        self.k=k\n",
    "#         print(self.q.shape)\n",
    "        q_t=tf.expand_dims(self.q,1)\n",
    "#         self.q=tf.transpose(self.q)\n",
    "        score=(self.Wq(self.q)*self.Wk(self.k))/math.sqrt(n)\n",
    "        attention_wts=tf.nn.softmax(score,axis=1)\n",
    "#         print(attention_wts.shape)\n",
    "        context_vector=(attention_wts*self.v)\n",
    "        context_vector=tf.reduce_sum(context_vector,axis=1)\n",
    "#         print(context_vector.shape)\n",
    "        return context_vector,attention_wts\n",
    "    \n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "        \n",
    "def fetch_vectors(string_list,pretrained_model, batch_size=64):\n",
    "    # inspired by https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "    model = transformers.TFDistilBertModel.from_pretrained(pretrained_model)\n",
    "    \n",
    "    fin_features = []\n",
    "    for data in chunks(string_list, batch_size):\n",
    "        tokenized = []\n",
    "        for x in data:\n",
    "            x = \" \".join(x.strip().split()[:300])\n",
    "            tok = tokenizer.encode(x, add_special_tokens=True)\n",
    "            tokenized.append(tok[:512])\n",
    "\n",
    "        max_len = 512\n",
    "        #bert variants have attention id, input id and segment id\n",
    "        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        input_ids = tf.convert_to_tensor(padded)\n",
    "        attention_mask = tf.convert_to_tensor(attention_mask)\n",
    "\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        features = last_hidden_states[0][:, 0, :].cpu().numpy()\n",
    "        fin_features.append(features)\n",
    "\n",
    "    fin_features = np.vstack(fin_features)\n",
    "    return fin_features\n",
    "\n",
    "        \n",
    "def distilbert_encoder_decoder_attention(maxlen,max_features,distilbert_embeddings):\n",
    "    #Creating LSTM  encoder neural model with no pretrained embeddings\n",
    "    encoder_inp=Input(shape=(maxlen,))\n",
    "    encoder_embed=Embedding(distilbert_embeddings.shape[0],embed_size,weights=[distilbert_embeddings])(encoder_inp)\n",
    "    print(encoder_inp.shape)\n",
    "#     encoder_embed_attention=ma.MiniAttentionBlock(None,None,None,keras.regularizers.L2(l2=0.02),None,None,None,None,None)(encoder_embed)\n",
    "    encoder_lstm_cell=LSTM(60,return_state='True')\n",
    "    encoder_outputs,encoder_state_flstm_h,encoder_state_flstm_c=encoder_lstm_cell(encoder_embed)\n",
    "    print(f'Encoder Ouputs Shape{encoder_outputs.shape}')\n",
    "    encoded_states=[encoder_state_flstm_h,encoder_state_flstm_c]\n",
    "    \n",
    "    #Creating LSTM decoder model and feeding the output states (h,c) of lstm of encoders\n",
    "    decoder_inp=Input(shape=(maxlen,))\n",
    "    decoder_embed=Embedding(distilbert_embeddings.shape[0],embed_size,weights=[distilbert_embeddings])(decoder_inp)\n",
    "    scaled_dot_product_attention=Scaled_Dot_Product_Self_Attention(60)\n",
    "    \n",
    "    decoder_embed_attention_h,decoder_embed_wghts_h=scaled_dot_product_attention(encoder_state_flstm_h,encoder_state_flstm_h,encoder_outputs,64)\n",
    "    decoder_embed_attention_c,decoder_embed_wghts_c=scaled_dot_product_attention(encoder_state_flstm_c,encoder_state_flstm_c,encoder_outputs,64)\n",
    "#     print(decoder_embed_wghts)\n",
    "    decoder_lstm_cell=LSTM(60,return_sequences='True',return_state=True)\n",
    "    decoder_outputs,decoder_state_lstm_h,decoder_state_lstm_c=decoder_lstm_cell(decoder_embed,initial_state=[decoder_embed_wghts_h,decoder_embed_wghts_c])\n",
    "#     decoderoutputs,_,_=decoder_lstm_cell(decoder_embed,initial_state=encoded_states)\n",
    "    \n",
    "    decoder_dense_cell=Dense(16,activation='relu')\n",
    "    decoder_d_output=decoder_dense_cell(decoder_outputs)\n",
    "    decoder_dense_cell2=Dense(1,activation='sigmoid')\n",
    "    decoder_output=decoder_dense_cell2(decoder_d_output)\n",
    "    model=Model([encoder_inp,decoder_inp],decoder_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# transformer_layer = (\n",
    "#         transformers.TFDistilBertModel\n",
    "#         .from_pretrained('distilbert-base-multilingual-cased'))\n",
    "# embedding_matrix,embedding_vector=build_model(transformer_layer,maxlen)\n",
    "# embedding_matrix=tf.keras.layers.Reshape((maxlen, 768))(embedding_matrix)\n",
    "distilbert_embeddings = fetch_vectors(train.text.values,'distilbert-base-uncased')\n",
    "\n",
    "model=distilbert_encoder_decoder_attention(maxlen,max_features,distilbert_embeddings)  \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "plot_model(\n",
    "    model,to_file=\"distilbert_encoder_decoder_attention.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96)\n",
    "train_y = np.asarray(train_y).astype('float32').reshape((-1,1))\n",
    "test_y = np.asarray(test_y).astype('float32').reshape((-1,1)) \n",
    "model.fit([train_x,train_x],train_y,batch_size=512,epochs=2,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wx6VlF96Evuz"
   },
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Bert pretrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAZowMfpNyEj",
    "outputId": "59771d7c-49b5-4fc8-ccf7-afebcd8a28e3"
   },
   "outputs": [],
   "source": [
    "pip install transformers==4.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Mpp9HWAPKiWF",
    "outputId": "668a3ad6-3d0d-4c8b-aae4-609c84f8f0dd"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yrrMfRVEKtp1"
   },
   "outputs": [],
   "source": [
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UIaowMm8Ktmb"
   },
   "outputs": [],
   "source": [
    "X=data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_it8fiGDKtkg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVJNpuYdXztJ",
    "outputId": "e99df950-98b1-4f63-e6c1-7139b33f3ed5"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "v08F7xpaEvVa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\anaconda3\\envs\\gput\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "739831ec7ff3491e8bd07e09b8727b27",
      "bb4fd078762149b690e33ef9e69c160a",
      "be88abeaaff34c59ab8a1152a2e5993e",
      "df825fa8b14b4331bc1af084ab53a762",
      "e4663f377d4d404b8b1a50db3e792b3f",
      "1761aeb84902489aa02719f6d1c61cba",
      "ab60e09965534940b72a59fe4cf881f3",
      "1e0ed5c17f1a4409ab4cf16e9ddaf58b",
      "b54c211621414bc2a6725e50adccf4e0",
      "35d1a58b725148c789d4433a389bc18c",
      "bc938e806e0140c48c71dff5b107c7ee",
      "0c7dddb70e974b36abf6a15a96499e22",
      "234a2538ad8f404691c49744a4d6f084",
      "10b75deaa9054120a2efb6b2229b340f",
      "bb328f67ab1941e186df2eed74c1bc67",
      "ad22a37b25c84a6f8d6638a6bad4c428",
      "f7c5badc22134af59f746c7f419cc7fc",
      "e4492c0baae9487abf973dc066dfc4be",
      "5ea0d93842474d059a353cdfef5be7ec",
      "83a1e29012e94f9497549187a620d88e",
      "dbd2a2e97cda4631b06478b31a94413b",
      "23cc9eeafecc46c1a0c6bfd523a2ad9a",
      "f54e1912ccce4acd8129e31bcca8524f",
      "c6ea156dccc9441cb350b4e438b3142e",
      "3fc8b6dff31e46e18949e4f1fc27be72",
      "4b793fedeae8483aa518da1e28d6008e",
      "6e5833793ca7421fbbc5d9335d39360a",
      "91aa69cd047b409a9fa1f885c4cfa77e",
      "ad26bc29f16847b5bf67c341d57880c5",
      "235f96b1971a4c4c90cf51edfe7e0972",
      "1cc8148b93ee409885733aa8de8b8b52",
      "0b4b3a952cf445f7ae054fe4c4630e2b",
      "9532d32f63304fdc93a377eff4f50f78",
      "e6833e1da8fb4b2a861ed139ce7262a0",
      "113c0dc2373743009dd30175868dbeb9",
      "ab9f16f55f154eeb99676f84cd11d91a",
      "56071b3cec42448c950bb81e0bc08c0b",
      "4cdf363490764306974c8609fa30e1a3",
      "a838bf7ad08f41e29f04322f3ca6a4ab",
      "b5f5ae37f6944b4087a9a171b52a44f2",
      "710e44525d984fdca9df9f0b50ba8236",
      "1d01e4a058234953b2bdcb57dfeafd77",
      "cb00b5440a9c432aa67b2cf4f8405fbd",
      "771c5919799a4dba87162b4aedbea88d"
     ]
    },
    "id": "7mn9Kr1bEvTW",
    "outputId": "6b833329-a418-44c7-ce00-1819f7d046c5"
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vAtFx5UAUe0W"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(list(X_test), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "C_Id0j2FW5VD"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NjaD2KfSUew4"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = Dataset(train_encodings, list(y_train))\n",
    "valid_dataset = Dataset(valid_encodings, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "chpnrT2IUeeR"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JMMAX-roVGHQ"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "d953d919579a417d86ea282c008194b2",
      "543d24a938584527a63373019025d0fa",
      "df4889c8e84c48b3b9d1e0fdcc58905e",
      "45f0a3c8ed594bab940a74b02d7aca11",
      "16373830874940da886be468776fbf11",
      "d142d2eaae094bf280c3f5c31675f80e",
      "70b6907a06c64e87bc43328b5540f22f",
      "b3419d96271946bcb64b466f3f26391a",
      "b3cee00948d9427db8fff8630fd91bc0",
      "2a567bc1b6a641c8baef8a131c7fde1b",
      "d67c5cf6e1ab4d95b316cf9421480dfe"
     ]
    },
    "id": "ujT_f3O4Uea4",
    "outputId": "3ac521f5-0471-4574-9a1a-e6a6b10f5b16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 268M/268M [06:51<00:00, 651kB/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3wdwK204VBJq"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "\n",
    "            ### Prepare data\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss, logits = outputs['loss'], outputs['logits']\n",
    "\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += labels.size(0)\n",
    "\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vwz1XJHpVBGc",
    "outputId": "d9c3ec2c-1835-489a-f14c-d84eafa3ed43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/0003 | Batch 0000/0524 | Loss: 0.4931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c2351eb34012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m### Backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gput\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gput\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        \n",
    "        ### Prepare data\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        ### Forward\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits = outputs['loss'], outputs['logits']\n",
    "        \n",
    "        ### Backward\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        ### Logging\n",
    "        if not batch_idx % 250:\n",
    "            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
    "                   f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "            \n",
    "    model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQuvp6BsVBEE"
   },
   "outputs": [],
   "source": [
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, valid_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J__Tc994VBBy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWA25uVhEvP6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nd9uuoJ2EvNY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87s9upaXEvLC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgSd6w4sEvHj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpHA-fMgsNca"
   },
   "outputs": [],
   "source": [
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYKwH7-hspKs"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch.nn.functional as f\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "    temp = query.bmm(key.transpose(1, 2))\n",
    "    scale = query.size(-1) ** 0.5\n",
    "    softmax = f.softmax(temp / scale, dim=-1)\n",
    "    return softmax.bmm(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwTszEuEsigb"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, dim_in: int, dim_q: int, dim_k: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(dim_in, dim_q)\n",
    "        self.k = nn.Linear(dim_in, dim_k)\n",
    "        self.v = nn.Linear(dim_in, dim_k)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        return scaled_dot_product_attention(self.q(query), self.k(key), self.v(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIjIoiFgsic-"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, dim_in: int, dim_q: int, dim_k: int):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(dim_in, dim_q, dim_k) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * dim_k, dim_in)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        return self.linear(\n",
    "            torch.cat([h(query, key, value) for h in self.heads], dim=-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10nZ-_5Rs4Kl"
   },
   "outputs": [],
   "source": [
    "\n",
    "def position_encoding(\n",
    "    seq_len: int, dim_model: int, device: torch.device = torch.device(\"cpu\"),\n",
    ") -> Tensor:\n",
    "    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n",
    "    dim = torch.arange(dim_model, dtype=torch.float, device=device).reshape(1, 1, -1)\n",
    "    phase = pos / (1e4 ** (dim // dim_model))\n",
    "\n",
    "    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPmxs_pos4HM"
   },
   "outputs": [],
   "source": [
    "def feed_forward(dim_input: int = 512, dim_feedforward: int = 2048) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim_input, dim_feedforward),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(dim_feedforward, dim_input),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_c95LSws4Fw"
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm = nn.LayerNorm(dimension)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, *tensors: Tensor) -> Tensor:\n",
    "        # Assume that the \"query\" tensor is given first, so we can compute the\n",
    "        # residual.  This matches the signature of 'MultiHeadAttention'.\n",
    "        return self.norm(tensors[0] + self.dropout(self.sublayer(*tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jStqYy1Ps4Di"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 6,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_q = dim_k = max(dim_model // num_heads, 1)\n",
    "        self.attention = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.feed_forward = Residual(\n",
    "            feed_forward(dim_model, dim_feedforward),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        src = self.attention(src, src, src)\n",
    "        return self.feed_forward(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGO1on0Jsiao"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 6,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        seq_len, dimension = src.size(1), src.size(2)\n",
    "        src += position_encoding(seq_len, dimension)\n",
    "        for layer in self.layers:\n",
    "            src = layer(src)\n",
    "\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlqIwM5AsiX2"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 6,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_q = dim_k = max(dim_model // num_heads, 1)\n",
    "        self.attention_1 = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.attention_2 = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.feed_forward = Residual(\n",
    "            feed_forward(dim_model, dim_feedforward),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor) -> Tensor:\n",
    "        tgt = self.attention_1(tgt, tgt, tgt)\n",
    "        tgt = self.attention_2(tgt, memory, memory)\n",
    "        return self.feed_forward(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54qCwdr_tPNF"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 6,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerDecoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.linear = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor) -> Tensor:\n",
    "        seq_len, dimension = tgt.size(1), tgt.size(2)\n",
    "        tgt += position_encoding(seq_len, dimension)\n",
    "        for layer in self.layers:\n",
    "            tgt = layer(tgt, memory)\n",
    "\n",
    "        return torch.softmax(self.linear(tgt), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_9joeXetPJg"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_encoder_layers: int = 6,\n",
    "        num_decoder_layers: int = 6,\n",
    "        dim_model: int = 512, \n",
    "        num_heads: int = 6, \n",
    "        dim_feedforward: int = 2048, \n",
    "        dropout: float = 0.1, \n",
    "        activation: nn.Module = nn.ReLU(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(\n",
    "            num_layers=num_encoder_layers,\n",
    "            dim_model=dim_model,\n",
    "            num_heads=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(\n",
    "            num_layers=num_decoder_layers,\n",
    "            dim_model=dim_model,\n",
    "            num_heads=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor) -> Tensor:\n",
    "        return self.decoder(tgt, self.encoder(src))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ikZnzqItdQW",
    "outputId": "a4f561e8-b36b-40e4-a818-03186ae1e555"
   },
   "outputs": [],
   "source": [
    "src = torch.rand(64, 32, 512)\n",
    "tgt = torch.rand(64, 16, 512)\n",
    "out = Transformer()(src, tgt)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcdcjEhKs7ka"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SlSXwv20aFh"
   },
   "outputs": [],
   "source": [
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2B-SLZZDxGC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GqsTNhrDxDF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oz5SnUDDxAb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXR10JV90aCJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPNfgTqC0Z_0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcgsCHxPsNUi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCVkZEjKsNRr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXk4JgvesNPG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DL_Project_Final.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01adab46a2924358b5fab6d9fcc2a778": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0834e6d2d3af4abc9e32f46f042619de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b4b3a952cf445f7ae054fe4c4630e2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c7dddb70e974b36abf6a15a96499e22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_234a2538ad8f404691c49744a4d6f084",
       "IPY_MODEL_10b75deaa9054120a2efb6b2229b340f",
       "IPY_MODEL_bb328f67ab1941e186df2eed74c1bc67"
      ],
      "layout": "IPY_MODEL_ad22a37b25c84a6f8d6638a6bad4c428"
     }
    },
    "0e4d92ca103b4eefbac988b4697d1a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ec8aa70bd61401bb8c9895d220a8f73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3da562f0cc34b75855f20e7e7ed58e2",
      "placeholder": "​",
      "style": "IPY_MODEL_a49d617090fd4f6aaf3f6ea15a362a66",
      "value": "Downloading: 100%"
     }
    },
    "10b75deaa9054120a2efb6b2229b340f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ea0d93842474d059a353cdfef5be7ec",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83a1e29012e94f9497549187a620d88e",
      "value": 231508
     }
    },
    "113c0dc2373743009dd30175868dbeb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a838bf7ad08f41e29f04322f3ca6a4ab",
      "placeholder": "​",
      "style": "IPY_MODEL_b5f5ae37f6944b4087a9a171b52a44f2",
      "value": "Downloading: 100%"
     }
    },
    "133ae031a07348a49782f42d87cb6af5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e414e0fb10e646148377bdc1d78f3125",
      "placeholder": "​",
      "style": "IPY_MODEL_6382eac6b2464a6db2664a9f4f7bfe1f",
      "value": " 483/483 [00:00&lt;00:00, 3.20kB/s]"
     }
    },
    "16373830874940da886be468776fbf11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1761aeb84902489aa02719f6d1c61cba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c5a9d583b5d40918ad696bb28a3888c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cc8148b93ee409885733aa8de8b8b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d01e4a058234953b2bdcb57dfeafd77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e0ed5c17f1a4409ab4cf16e9ddaf58b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20ba82462b99450a8f6adc137cdf87d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "234a2538ad8f404691c49744a4d6f084": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7c5badc22134af59f746c7f419cc7fc",
      "placeholder": "​",
      "style": "IPY_MODEL_e4492c0baae9487abf973dc066dfc4be",
      "value": "Downloading: 100%"
     }
    },
    "235f96b1971a4c4c90cf51edfe7e0972": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23cc9eeafecc46c1a0c6bfd523a2ad9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a567bc1b6a641c8baef8a131c7fde1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d70fc5fdbb54419a9fd88259781ee0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33bc2d45177a4281954402114bbdd879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d70fc5fdbb54419a9fd88259781ee0f",
      "placeholder": "​",
      "style": "IPY_MODEL_0e4d92ca103b4eefbac988b4697d1a33",
      "value": " 347M/347M [00:06&lt;00:00, 52.4MB/s]"
     }
    },
    "34c9d132f3be4a52a61a269e0c4f87c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35d1a58b725148c789d4433a389bc18c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38789e22afbe4954a115a545df74de1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6f7ac6ac0545de9baab3a7b0f82aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3fc8b6dff31e46e18949e4f1fc27be72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_235f96b1971a4c4c90cf51edfe7e0972",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1cc8148b93ee409885733aa8de8b8b52",
      "value": 466062
     }
    },
    "455a37bd3c704894b78e2a21548733b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45f0a3c8ed594bab940a74b02d7aca11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a567bc1b6a641c8baef8a131c7fde1b",
      "placeholder": "​",
      "style": "IPY_MODEL_d67c5cf6e1ab4d95b316cf9421480dfe",
      "value": " 256M/256M [00:08&lt;00:00, 35.8MB/s]"
     }
    },
    "4b793fedeae8483aa518da1e28d6008e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b4b3a952cf445f7ae054fe4c4630e2b",
      "placeholder": "​",
      "style": "IPY_MODEL_9532d32f63304fdc93a377eff4f50f78",
      "value": " 455k/455k [00:00&lt;00:00, 541kB/s]"
     }
    },
    "4cdf363490764306974c8609fa30e1a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "543d24a938584527a63373019025d0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d142d2eaae094bf280c3f5c31675f80e",
      "placeholder": "​",
      "style": "IPY_MODEL_70b6907a06c64e87bc43328b5540f22f",
      "value": "Downloading: 100%"
     }
    },
    "56071b3cec42448c950bb81e0bc08c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb00b5440a9c432aa67b2cf4f8405fbd",
      "placeholder": "​",
      "style": "IPY_MODEL_771c5919799a4dba87162b4aedbea88d",
      "value": " 483/483 [00:00&lt;00:00, 2.83kB/s]"
     }
    },
    "5bd94434fefa42e3a5409f7772d97337": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60064c69f71141468f9019ef68ab8c46",
      "placeholder": "​",
      "style": "IPY_MODEL_c21fb1c2c84149c0bfa9a45f0bb53e9c",
      "value": " 226k/226k [00:00&lt;00:00, 267kB/s]"
     }
    },
    "5d2b3a06693a48bc93fab26a19a5485c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0b7f0521dc64671a07dbd3cfd716a6d",
      "placeholder": "​",
      "style": "IPY_MODEL_c1594b8f5603492e8dc657271ab0ccc7",
      "value": "Downloading: 100%"
     }
    },
    "5ea0d93842474d059a353cdfef5be7ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60064c69f71141468f9019ef68ab8c46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61925f32545c421d9581c455d76f4cc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5a9d583b5d40918ad696bb28a3888c",
      "placeholder": "​",
      "style": "IPY_MODEL_72bff3722aa347fd8c5b804191a2e81b",
      "value": "Downloading: 100%"
     }
    },
    "6382eac6b2464a6db2664a9f4f7bfe1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "650f590da14d4e42a5eeb8f476a3aa5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a171f9dd80e40e6a71c2ee616011961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d23264350ce422d94d165791fa23c2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e5833793ca7421fbbc5d9335d39360a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70b6907a06c64e87bc43328b5540f22f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "710e44525d984fdca9df9f0b50ba8236": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72bff3722aa347fd8c5b804191a2e81b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "739831ec7ff3491e8bd07e09b8727b27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb4fd078762149b690e33ef9e69c160a",
       "IPY_MODEL_be88abeaaff34c59ab8a1152a2e5993e",
       "IPY_MODEL_df825fa8b14b4331bc1af084ab53a762"
      ],
      "layout": "IPY_MODEL_e4663f377d4d404b8b1a50db3e792b3f"
     }
    },
    "74c2e9350ae24df1948734a3a7dc83aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a3d1bda315fe4492bd2d7ec4186929dc",
       "IPY_MODEL_d160f65533b443e481e20a24442be8e6",
       "IPY_MODEL_d6ebb00bfc904f78a2cee7870f54e6ac"
      ],
      "layout": "IPY_MODEL_34c9d132f3be4a52a61a269e0c4f87c7"
     }
    },
    "771c5919799a4dba87162b4aedbea88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "797e519155264d0a939567006d4f41d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83a1e29012e94f9497549187a620d88e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c1dcb1d2bfd4465b56fdf572de929a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61925f32545c421d9581c455d76f4cc1",
       "IPY_MODEL_ab47b6b72b9a4bdba3f902b398a29100",
       "IPY_MODEL_5bd94434fefa42e3a5409f7772d97337"
      ],
      "layout": "IPY_MODEL_c2d1b2d858b04b038171eed62b4af26e"
     }
    },
    "91aa69cd047b409a9fa1f885c4cfa77e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9532d32f63304fdc93a377eff4f50f78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98b20bd85ec3423882b5546569b11c16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0ec8aa70bd61401bb8c9895d220a8f73",
       "IPY_MODEL_da88fa9c0f25458582d83347cd3b03eb",
       "IPY_MODEL_db04127895bb4fbd883b83eedf0b7271"
      ],
      "layout": "IPY_MODEL_c58e771d11fc4ef48b553525750687d0"
     }
    },
    "a1977a373ddb4311b89fa8a8bcf2ac72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d23264350ce422d94d165791fa23c2e",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c87900a7087b41958925913c41d0c86a",
      "value": 363423424
     }
    },
    "a3d1bda315fe4492bd2d7ec4186929dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38789e22afbe4954a115a545df74de1e",
      "placeholder": "​",
      "style": "IPY_MODEL_20ba82462b99450a8f6adc137cdf87d4",
      "value": "Downloading: 100%"
     }
    },
    "a49d617090fd4f6aaf3f6ea15a362a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8233f6477ce45c0a99edccf26aef616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_455a37bd3c704894b78e2a21548733b8",
      "placeholder": "​",
      "style": "IPY_MODEL_0834e6d2d3af4abc9e32f46f042619de",
      "value": "Downloading: 100%"
     }
    },
    "a838bf7ad08f41e29f04322f3ca6a4ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a86f18b4710a4c58a8a8df2ed69a3198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d2b3a06693a48bc93fab26a19a5485c",
       "IPY_MODEL_a1977a373ddb4311b89fa8a8bcf2ac72",
       "IPY_MODEL_33bc2d45177a4281954402114bbdd879"
      ],
      "layout": "IPY_MODEL_fb76c7033911464dbab81df8e2a0bc07"
     }
    },
    "ab47b6b72b9a4bdba3f902b398a29100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0ee589694e44cdcb433c51e7bb0ce4a",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8d97e66a60244eba78eafceec0b5fe5",
      "value": 231508
     }
    },
    "ab60e09965534940b72a59fe4cf881f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab9f16f55f154eeb99676f84cd11d91a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_710e44525d984fdca9df9f0b50ba8236",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d01e4a058234953b2bdcb57dfeafd77",
      "value": 483
     }
    },
    "ad22a37b25c84a6f8d6638a6bad4c428": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad26bc29f16847b5bf67c341d57880c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0b7f0521dc64671a07dbd3cfd716a6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0f87cd130f446748a78395c363a695a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3419d96271946bcb64b466f3f26391a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3cee00948d9427db8fff8630fd91bc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b54c211621414bc2a6725e50adccf4e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5f5ae37f6944b4087a9a171b52a44f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb328f67ab1941e186df2eed74c1bc67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbd2a2e97cda4631b06478b31a94413b",
      "placeholder": "​",
      "style": "IPY_MODEL_23cc9eeafecc46c1a0c6bfd523a2ad9a",
      "value": " 226k/226k [00:00&lt;00:00, 192kB/s]"
     }
    },
    "bb4fd078762149b690e33ef9e69c160a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1761aeb84902489aa02719f6d1c61cba",
      "placeholder": "​",
      "style": "IPY_MODEL_ab60e09965534940b72a59fe4cf881f3",
      "value": "Downloading: 100%"
     }
    },
    "bc938e806e0140c48c71dff5b107c7ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be88abeaaff34c59ab8a1152a2e5993e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e0ed5c17f1a4409ab4cf16e9ddaf58b",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b54c211621414bc2a6725e50adccf4e0",
      "value": 28
     }
    },
    "c0ee589694e44cdcb433c51e7bb0ce4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1594b8f5603492e8dc657271ab0ccc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c21fb1c2c84149c0bfa9a45f0bb53e9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2d1b2d858b04b038171eed62b4af26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3da562f0cc34b75855f20e7e7ed58e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c58e771d11fc4ef48b553525750687d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6ea156dccc9441cb350b4e438b3142e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91aa69cd047b409a9fa1f885c4cfa77e",
      "placeholder": "​",
      "style": "IPY_MODEL_ad26bc29f16847b5bf67c341d57880c5",
      "value": "Downloading: 100%"
     }
    },
    "c87900a7087b41958925913c41d0c86a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb00b5440a9c432aa67b2cf4f8405fbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cce54d22ae724427815e2b6652ad851a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d142d2eaae094bf280c3f5c31675f80e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d160f65533b443e481e20a24442be8e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4ebdd2090ad44299f8b1962055fa08e",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0f87cd130f446748a78395c363a695a",
      "value": 466062
     }
    },
    "d4ebdd2090ad44299f8b1962055fa08e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d67c5cf6e1ab4d95b316cf9421480dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6ebb00bfc904f78a2cee7870f54e6ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e620710096be4553bf1211e4f80b2b39",
      "placeholder": "​",
      "style": "IPY_MODEL_797e519155264d0a939567006d4f41d4",
      "value": " 455k/455k [00:01&lt;00:00, 475kB/s]"
     }
    },
    "d7526ff8cc314ea4aadc4d05f839316c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8233f6477ce45c0a99edccf26aef616",
       "IPY_MODEL_d88617cd89d44cc0a38040325ef3dc20",
       "IPY_MODEL_133ae031a07348a49782f42d87cb6af5"
      ],
      "layout": "IPY_MODEL_01adab46a2924358b5fab6d9fcc2a778"
     }
    },
    "d88617cd89d44cc0a38040325ef3dc20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1693d2cd5ac424891a448896d3a24b3",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df46e11b06f14e72b7dcb6f31e22eb74",
      "value": 483
     }
    },
    "d953d919579a417d86ea282c008194b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_543d24a938584527a63373019025d0fa",
       "IPY_MODEL_df4889c8e84c48b3b9d1e0fdcc58905e",
       "IPY_MODEL_45f0a3c8ed594bab940a74b02d7aca11"
      ],
      "layout": "IPY_MODEL_16373830874940da886be468776fbf11"
     }
    },
    "da88fa9c0f25458582d83347cd3b03eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a171f9dd80e40e6a71c2ee616011961",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_650f590da14d4e42a5eeb8f476a3aa5a",
      "value": 28
     }
    },
    "db04127895bb4fbd883b83eedf0b7271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cce54d22ae724427815e2b6652ad851a",
      "placeholder": "​",
      "style": "IPY_MODEL_3b6f7ac6ac0545de9baab3a7b0f82aac",
      "value": " 28.0/28.0 [00:00&lt;00:00, 272B/s]"
     }
    },
    "dbd2a2e97cda4631b06478b31a94413b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df46e11b06f14e72b7dcb6f31e22eb74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df4889c8e84c48b3b9d1e0fdcc58905e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3419d96271946bcb64b466f3f26391a",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3cee00948d9427db8fff8630fd91bc0",
      "value": 267967963
     }
    },
    "df825fa8b14b4331bc1af084ab53a762": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35d1a58b725148c789d4433a389bc18c",
      "placeholder": "​",
      "style": "IPY_MODEL_bc938e806e0140c48c71dff5b107c7ee",
      "value": " 28.0/28.0 [00:00&lt;00:00, 550B/s]"
     }
    },
    "e1693d2cd5ac424891a448896d3a24b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e414e0fb10e646148377bdc1d78f3125": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4492c0baae9487abf973dc066dfc4be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4663f377d4d404b8b1a50db3e792b3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e620710096be4553bf1211e4f80b2b39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6833e1da8fb4b2a861ed139ce7262a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_113c0dc2373743009dd30175868dbeb9",
       "IPY_MODEL_ab9f16f55f154eeb99676f84cd11d91a",
       "IPY_MODEL_56071b3cec42448c950bb81e0bc08c0b"
      ],
      "layout": "IPY_MODEL_4cdf363490764306974c8609fa30e1a3"
     }
    },
    "e8d97e66a60244eba78eafceec0b5fe5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f54e1912ccce4acd8129e31bcca8524f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6ea156dccc9441cb350b4e438b3142e",
       "IPY_MODEL_3fc8b6dff31e46e18949e4f1fc27be72",
       "IPY_MODEL_4b793fedeae8483aa518da1e28d6008e"
      ],
      "layout": "IPY_MODEL_6e5833793ca7421fbbc5d9335d39360a"
     }
    },
    "f7c5badc22134af59f746c7f419cc7fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb76c7033911464dbab81df8e2a0bc07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
